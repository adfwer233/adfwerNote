---
title: "Lecture7: Learning 3"
---

## Decision Tree

### ID3 Algorithm

- If Attributes is empty, return the single-node tree, with the label the most common value of Target_attribute in Examples.

The maximum height of the decision tree is the size of Attributes set.

### C4.5

## Random Forest

- Different samples
- Different features

### Bootstrap Sample

- Drawn with replacement

### Construction

- Assume we have $n$ examples, $d$ features

- Bootstrap samples from training data
- Construct each decision tree with randomly sampled $K \approx \sqrt{d}$ features for each spilt

## Deep Learning

**Deep learning is algorithm that model high-level abstractions in data using architectures consisting of multiple nonlinear transformations.**

